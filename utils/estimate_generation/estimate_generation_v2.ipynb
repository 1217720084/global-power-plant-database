{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate generation v2\n",
    "\n",
    "Use advanced models for generation estimation in the Global Power Plant Database.\n",
    "Primary model is a two-hidden-layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import what we'll need and set parameters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers import Conv2D, Dropout, Activation, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pydot\n",
    "\n",
    "GPPD_FILENAME = '../../output_database/global_power_plant_database.csv'\n",
    "WEIGHTS_FILE = \"model/estimate_generation.h5\"\n",
    "VALIDATION_FRACTION = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_long</th>\n",
       "      <th>name</th>\n",
       "      <th>gppd_idnr</th>\n",
       "      <th>capacity_mw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>fuel1</th>\n",
       "      <th>fuel2</th>\n",
       "      <th>fuel3</th>\n",
       "      <th>...</th>\n",
       "      <th>owner</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>geolocation_source</th>\n",
       "      <th>year_of_capacity_data</th>\n",
       "      <th>generation_gwh_2013</th>\n",
       "      <th>generation_gwh_2014</th>\n",
       "      <th>generation_gwh_2015</th>\n",
       "      <th>generation_gwh_2016</th>\n",
       "      <th>estimated_generation_gwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kajaki Hydroelectric Power Plant Afghanistan</td>\n",
       "      <td>GEODB0040538</td>\n",
       "      <td>33.00</td>\n",
       "      <td>32.3220</td>\n",
       "      <td>65.1190</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>http://globalenergyobservatory.org</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mahipar Hydroelectric Power Plant Afghanistan</td>\n",
       "      <td>GEODB0040541</td>\n",
       "      <td>66.00</td>\n",
       "      <td>34.5560</td>\n",
       "      <td>69.4787</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>http://globalenergyobservatory.org</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Naghlu Dam Hydroelectric Power Plant Afghanistan</td>\n",
       "      <td>GEODB0040534</td>\n",
       "      <td>100.00</td>\n",
       "      <td>34.6410</td>\n",
       "      <td>69.7170</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>http://globalenergyobservatory.org</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Nangarhar (Darunta) Hydroelectric Power Plant ...</td>\n",
       "      <td>GEODB0040536</td>\n",
       "      <td>11.55</td>\n",
       "      <td>34.4847</td>\n",
       "      <td>70.3633</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>http://globalenergyobservatory.org</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Northwest Kabul Power Plant Afghanistan</td>\n",
       "      <td>GEODB0040540</td>\n",
       "      <td>42.00</td>\n",
       "      <td>34.5638</td>\n",
       "      <td>69.1134</td>\n",
       "      <td>Gas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>http://globalenergyobservatory.org</td>\n",
       "      <td>GEODB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country country_long                                               name  \\\n",
       "0     AFG  Afghanistan       Kajaki Hydroelectric Power Plant Afghanistan   \n",
       "1     AFG  Afghanistan      Mahipar Hydroelectric Power Plant Afghanistan   \n",
       "2     AFG  Afghanistan   Naghlu Dam Hydroelectric Power Plant Afghanistan   \n",
       "3     AFG  Afghanistan  Nangarhar (Darunta) Hydroelectric Power Plant ...   \n",
       "4     AFG  Afghanistan            Northwest Kabul Power Plant Afghanistan   \n",
       "\n",
       "      gppd_idnr  capacity_mw  latitude  longitude  fuel1 fuel2 fuel3  \\\n",
       "0  GEODB0040538        33.00   32.3220    65.1190  Hydro   NaN   NaN   \n",
       "1  GEODB0040541        66.00   34.5560    69.4787  Hydro   NaN   NaN   \n",
       "2  GEODB0040534       100.00   34.6410    69.7170  Hydro   NaN   NaN   \n",
       "3  GEODB0040536        11.55   34.4847    70.3633  Hydro   NaN   NaN   \n",
       "4  GEODB0040540        42.00   34.5638    69.1134    Gas   NaN   NaN   \n",
       "\n",
       "             ...            owner  source                                 url  \\\n",
       "0            ...              NaN   GEODB  http://globalenergyobservatory.org   \n",
       "1            ...              NaN   GEODB  http://globalenergyobservatory.org   \n",
       "2            ...              NaN   GEODB  http://globalenergyobservatory.org   \n",
       "3            ...              NaN   GEODB  http://globalenergyobservatory.org   \n",
       "4            ...              NaN   GEODB  http://globalenergyobservatory.org   \n",
       "\n",
       "  geolocation_source year_of_capacity_data generation_gwh_2013  \\\n",
       "0              GEODB                2017.0                 NaN   \n",
       "1              GEODB                2017.0                 NaN   \n",
       "2              GEODB                2017.0                 NaN   \n",
       "3              GEODB                2017.0                 NaN   \n",
       "4              GEODB                2017.0                 NaN   \n",
       "\n",
       "   generation_gwh_2014  generation_gwh_2015  generation_gwh_2016  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   estimated_generation_gwh  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in database\n",
    "df = pd.read_csv(GPPD_FILENAME)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                     25657\n",
       "country_long                25657\n",
       "name                        25637\n",
       "gppd_idnr                   25657\n",
       "capacity_mw                 25657\n",
       "latitude                    25657\n",
       "longitude                   25657\n",
       "fuel1                       25657\n",
       "fuel2                        1670\n",
       "fuel3                         295\n",
       "fuel4                         107\n",
       "commissioning_year          13933\n",
       "owner                       17157\n",
       "source                      25657\n",
       "url                         25657\n",
       "geolocation_source          25657\n",
       "year_of_capacity_data       16065\n",
       "generation_gwh_2013           371\n",
       "generation_gwh_2014           386\n",
       "generation_gwh_2015           887\n",
       "generation_gwh_2016          8326\n",
       "estimated_generation_gwh    24633\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show count for number of valid entries in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.00000000e+00   2.89000000e+02   4.72078000e+01   1.10057000e+01\n",
      "    1.98100000e+03   0.00000000e+00]\n",
      " [  8.00000000e+00   5.00000000e+02   4.72696000e+01   1.09678000e+01\n",
      "    1.98100000e+03   0.00000000e+00]\n",
      " [  4.30000000e+01   2.25000000e+03   3.02483000e+01   3.09471000e+01\n",
      "    2.01400000e+03   1.00000000e+00]\n",
      " ..., \n",
      " [  1.57000000e+02   2.80000000e+01   1.43611000e+01   1.08720300e+02\n",
      "    2.01400000e+03   0.00000000e+00]\n",
      " [  1.57000000e+02   1.95000000e+01   1.21526000e+01   1.08378700e+02\n",
      "    2.01000000e+03   0.00000000e+00]\n",
      " [  1.57000000e+02   3.00000000e+01   1.58600000e+01   1.07653800e+02\n",
      "    2.00900000e+03   0.00000000e+00]]\n",
      "[[ 0.04692255]\n",
      " [ 0.02934475]\n",
      " [ 0.00674784]\n",
      " ..., \n",
      " [ 0.41992825]\n",
      " [ 0.46247512]\n",
      " [ 0.46689498]]\n",
      "8238\n",
      "8238\n"
     ]
    }
   ],
   "source": [
    "# prepare data for training\n",
    "\n",
    "# convert string-type columns to categories (assume no NaNs in these columns)\n",
    "factorized_countries,country_key = df['country'].factorize()\n",
    "df['country'] = factorized_countries\n",
    "factorized_fuel1,fuel1_key = df['fuel1'].factorize()\n",
    "df['fuel1'] = factorized_fuel1\n",
    "\n",
    "# convert numerical columns to np array to use as predictor variables and remove NaNs\n",
    "X_columns = ['country','capacity_mw','latitude','longitude','commissioning_year','fuel1']\n",
    "df_No_NaN = df[X_columns + ['generation_gwh_2016']].dropna(how='any')\n",
    "X_data = df_No_NaN[X_columns].as_matrix()\n",
    "\n",
    "# calculate capacity factor to use as predicted variable\n",
    "df_No_NaN['capacity_factor'] = df_No_NaN.apply(lambda row:row['generation_gwh_2016']/(24.0*365.0*0.001*row['capacity_mw']),axis=1)\n",
    "y_column = ['capacity_factor']\n",
    "y_data = df_No_NaN[y_column].as_matrix()\n",
    "\n",
    "# show results\n",
    "print(X_data)\n",
    "print(y_data)\n",
    "print(len(X_data))\n",
    "print(len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scaling values for input data\n",
    "\n",
    "mean_vals = np.mean(X_data,axis=0)\n",
    "range_vals = np.max(X_data,axis=0) - np.min(X_data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is: (6,)\n",
      "Model contains 34049 parameters.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 34,049\n",
      "Trainable params: 34,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# set up neural network\n",
    "\n",
    "INPUT_SHAPE = X_data[0].shape\n",
    "print(u\"Input shape is: {0}\".format(INPUT_SHAPE))\n",
    "DROPOUT_RATE = 0.15\n",
    "DENSE_LAYER_SIZE = 128\n",
    "\n",
    "def myNet():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x - mean_vals,input_shape = INPUT_SHAPE))   # placeholder for normalization\n",
    "    model.add(Dense(DENSE_LAYER_SIZE,activation='relu'))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(DENSE_LAYER_SIZE,activation='relu'))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(DENSE_LAYER_SIZE,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "    \n",
    "model = myNet()\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['mean_absolute_error'])\n",
    "print(\"Model contains {0} parameters.\".format(model.count_params()))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6590 samples, validate on 1648 samples\n",
      "Epoch 1/256\n",
      "6590/6590 [==============================] - 1s 152us/step - loss: 0.8625 - mean_absolute_error: 0.3745 - val_loss: 0.1406 - val_mean_absolute_error: 0.2477\n",
      "Epoch 2/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.3787 - mean_absolute_error: 0.2864 - val_loss: 0.0891 - val_mean_absolute_error: 0.2236\n",
      "Epoch 3/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.1281 - mean_absolute_error: 0.2272 - val_loss: 0.0633 - val_mean_absolute_error: 0.1993\n",
      "Epoch 4/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0785 - mean_absolute_error: 0.2045 - val_loss: 0.0635 - val_mean_absolute_error: 0.1980\n",
      "Epoch 5/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0713 - mean_absolute_error: 0.2027 - val_loss: 0.0658 - val_mean_absolute_error: 0.2005\n",
      "Epoch 6/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0772 - mean_absolute_error: 0.2036 - val_loss: 0.0652 - val_mean_absolute_error: 0.2012\n",
      "Epoch 7/256\n",
      "6590/6590 [==============================] - 0s 66us/step - loss: 0.0635 - mean_absolute_error: 0.1974 - val_loss: 0.0634 - val_mean_absolute_error: 0.2003\n",
      "Epoch 8/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0649 - mean_absolute_error: 0.1979 - val_loss: 0.0614 - val_mean_absolute_error: 0.1924\n",
      "Epoch 9/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0636 - mean_absolute_error: 0.1969 - val_loss: 0.0646 - val_mean_absolute_error: 0.1995\n",
      "Epoch 10/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0603 - mean_absolute_error: 0.1949 - val_loss: 0.0640 - val_mean_absolute_error: 0.2004\n",
      "Epoch 11/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0600 - mean_absolute_error: 0.1948 - val_loss: 0.0632 - val_mean_absolute_error: 0.2010\n",
      "Epoch 12/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0599 - mean_absolute_error: 0.1954 - val_loss: 0.0644 - val_mean_absolute_error: 0.2003\n",
      "Epoch 13/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0589 - mean_absolute_error: 0.1941 - val_loss: 0.0636 - val_mean_absolute_error: 0.1994\n",
      "Epoch 14/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0587 - mean_absolute_error: 0.1931 - val_loss: 0.0632 - val_mean_absolute_error: 0.1993\n",
      "Epoch 15/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0600 - mean_absolute_error: 0.1944 - val_loss: 0.0666 - val_mean_absolute_error: 0.2048\n",
      "Epoch 16/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0591 - mean_absolute_error: 0.1939 - val_loss: 0.0624 - val_mean_absolute_error: 0.1985\n",
      "Epoch 17/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0584 - mean_absolute_error: 0.1927 - val_loss: 0.0638 - val_mean_absolute_error: 0.1976\n",
      "Epoch 18/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0590 - mean_absolute_error: 0.1933 - val_loss: 0.0632 - val_mean_absolute_error: 0.1996\n",
      "Epoch 19/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0587 - mean_absolute_error: 0.1935 - val_loss: 0.0636 - val_mean_absolute_error: 0.1971\n",
      "Epoch 20/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0592 - mean_absolute_error: 0.1937 - val_loss: 0.0634 - val_mean_absolute_error: 0.1994\n",
      "Epoch 21/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0584 - mean_absolute_error: 0.1923 - val_loss: 0.0625 - val_mean_absolute_error: 0.1986\n",
      "Epoch 22/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0593 - mean_absolute_error: 0.1935 - val_loss: 0.0603 - val_mean_absolute_error: 0.1897\n",
      "Epoch 23/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0598 - mean_absolute_error: 0.1938 - val_loss: 0.0624 - val_mean_absolute_error: 0.1971\n",
      "Epoch 24/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0584 - mean_absolute_error: 0.1925 - val_loss: 0.0622 - val_mean_absolute_error: 0.1956\n",
      "Epoch 25/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0583 - mean_absolute_error: 0.1921 - val_loss: 0.0620 - val_mean_absolute_error: 0.1977\n",
      "Epoch 26/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0578 - mean_absolute_error: 0.1916 - val_loss: 0.0634 - val_mean_absolute_error: 0.1989\n",
      "Epoch 27/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0580 - mean_absolute_error: 0.1917 - val_loss: 0.0643 - val_mean_absolute_error: 0.1987\n",
      "Epoch 28/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0577 - mean_absolute_error: 0.1915 - val_loss: 0.0630 - val_mean_absolute_error: 0.1979\n",
      "Epoch 29/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0583 - mean_absolute_error: 0.1924 - val_loss: 0.0629 - val_mean_absolute_error: 0.1975\n",
      "Epoch 30/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0579 - mean_absolute_error: 0.1920 - val_loss: 0.0629 - val_mean_absolute_error: 0.1982\n",
      "Epoch 31/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0578 - mean_absolute_error: 0.1920 - val_loss: 0.0631 - val_mean_absolute_error: 0.1965\n",
      "Epoch 32/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0586 - mean_absolute_error: 0.1929 - val_loss: 0.0631 - val_mean_absolute_error: 0.1966\n",
      "Epoch 33/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0578 - mean_absolute_error: 0.1918 - val_loss: 0.0628 - val_mean_absolute_error: 0.1961\n",
      "Epoch 34/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0584 - mean_absolute_error: 0.1917 - val_loss: 0.0624 - val_mean_absolute_error: 0.1975\n",
      "Epoch 35/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0579 - mean_absolute_error: 0.1922 - val_loss: 0.0620 - val_mean_absolute_error: 0.1954\n",
      "Epoch 36/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0575 - mean_absolute_error: 0.1907 - val_loss: 0.0612 - val_mean_absolute_error: 0.1960\n",
      "Epoch 37/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0576 - mean_absolute_error: 0.1909 - val_loss: 0.0614 - val_mean_absolute_error: 0.1949\n",
      "Epoch 38/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0594 - mean_absolute_error: 0.1922 - val_loss: 0.0631 - val_mean_absolute_error: 0.1992\n",
      "Epoch 39/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0582 - mean_absolute_error: 0.1932 - val_loss: 0.0630 - val_mean_absolute_error: 0.1975\n",
      "Epoch 40/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0585 - mean_absolute_error: 0.1932 - val_loss: 0.0629 - val_mean_absolute_error: 0.1988\n",
      "Epoch 41/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0584 - mean_absolute_error: 0.1930 - val_loss: 0.0617 - val_mean_absolute_error: 0.1952\n",
      "Epoch 42/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0578 - mean_absolute_error: 0.1920 - val_loss: 0.0612 - val_mean_absolute_error: 0.1962\n",
      "Epoch 43/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0578 - mean_absolute_error: 0.1922 - val_loss: 0.0626 - val_mean_absolute_error: 0.1977\n",
      "Epoch 44/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0581 - mean_absolute_error: 0.1927 - val_loss: 0.0620 - val_mean_absolute_error: 0.1961\n",
      "Epoch 45/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0578 - mean_absolute_error: 0.1923 - val_loss: 0.0629 - val_mean_absolute_error: 0.1984\n",
      "Epoch 46/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0578 - mean_absolute_error: 0.1923 - val_loss: 0.0640 - val_mean_absolute_error: 0.1994\n",
      "Epoch 47/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0581 - mean_absolute_error: 0.1920 - val_loss: 0.0617 - val_mean_absolute_error: 0.1969\n",
      "Epoch 48/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0578 - mean_absolute_error: 0.1917 - val_loss: 0.0627 - val_mean_absolute_error: 0.1972\n",
      "Epoch 49/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0574 - mean_absolute_error: 0.1908 - val_loss: 0.0630 - val_mean_absolute_error: 0.1976\n",
      "Epoch 50/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0577 - mean_absolute_error: 0.1915 - val_loss: 0.0622 - val_mean_absolute_error: 0.1976\n",
      "Epoch 51/256\n",
      "6590/6590 [==============================] - 0s 66us/step - loss: 0.0574 - mean_absolute_error: 0.1906 - val_loss: 0.0618 - val_mean_absolute_error: 0.1972\n",
      "Epoch 52/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0578 - mean_absolute_error: 0.1915 - val_loss: 0.0625 - val_mean_absolute_error: 0.1969\n",
      "Epoch 53/256\n",
      "6590/6590 [==============================] - 0s 66us/step - loss: 0.0596 - mean_absolute_error: 0.1911 - val_loss: 0.0628 - val_mean_absolute_error: 0.1978\n",
      "Epoch 54/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0574 - mean_absolute_error: 0.1911 - val_loss: 0.0621 - val_mean_absolute_error: 0.1971\n",
      "Epoch 55/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0571 - mean_absolute_error: 0.1900 - val_loss: 0.0627 - val_mean_absolute_error: 0.1968\n",
      "Epoch 56/256\n",
      "6590/6590 [==============================] - 0s 66us/step - loss: 0.0571 - mean_absolute_error: 0.1901 - val_loss: 0.0617 - val_mean_absolute_error: 0.1979\n",
      "Epoch 57/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0574 - mean_absolute_error: 0.1911 - val_loss: 0.0617 - val_mean_absolute_error: 0.1948\n",
      "Epoch 58/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0574 - mean_absolute_error: 0.1910 - val_loss: 0.0625 - val_mean_absolute_error: 0.1986\n",
      "Epoch 59/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0577 - mean_absolute_error: 0.1916 - val_loss: 0.0634 - val_mean_absolute_error: 0.1979\n",
      "Epoch 60/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0575 - mean_absolute_error: 0.1915 - val_loss: 0.0624 - val_mean_absolute_error: 0.1971\n",
      "Epoch 61/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0573 - mean_absolute_error: 0.1907 - val_loss: 0.0615 - val_mean_absolute_error: 0.1961\n",
      "Epoch 62/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0573 - mean_absolute_error: 0.1908 - val_loss: 0.0614 - val_mean_absolute_error: 0.1967\n",
      "Epoch 63/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0568 - mean_absolute_error: 0.1900 - val_loss: 0.0625 - val_mean_absolute_error: 0.1978\n",
      "Epoch 64/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0564 - mean_absolute_error: 0.1896 - val_loss: 0.0609 - val_mean_absolute_error: 0.1945\n",
      "Epoch 65/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0573 - mean_absolute_error: 0.1891 - val_loss: 0.0600 - val_mean_absolute_error: 0.1920\n",
      "Epoch 66/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0558 - mean_absolute_error: 0.1877 - val_loss: 0.0553 - val_mean_absolute_error: 0.1810\n",
      "Epoch 67/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0562 - mean_absolute_error: 0.1883 - val_loss: 0.0607 - val_mean_absolute_error: 0.1933\n",
      "Epoch 68/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0556 - mean_absolute_error: 0.1874 - val_loss: 0.0613 - val_mean_absolute_error: 0.1937\n",
      "Epoch 69/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0560 - mean_absolute_error: 0.1882 - val_loss: 0.0614 - val_mean_absolute_error: 0.1919\n",
      "Epoch 70/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0554 - mean_absolute_error: 0.1865 - val_loss: 0.0581 - val_mean_absolute_error: 0.1890\n",
      "Epoch 71/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0544 - mean_absolute_error: 0.1847 - val_loss: 0.0568 - val_mean_absolute_error: 0.1885\n",
      "Epoch 72/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0539 - mean_absolute_error: 0.1837 - val_loss: 0.0580 - val_mean_absolute_error: 0.1890\n",
      "Epoch 73/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0547 - mean_absolute_error: 0.1852 - val_loss: 0.0591 - val_mean_absolute_error: 0.1909\n",
      "Epoch 74/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0542 - mean_absolute_error: 0.1840 - val_loss: 0.0565 - val_mean_absolute_error: 0.1868\n",
      "Epoch 75/256\n",
      "6590/6590 [==============================] - 1s 76us/step - loss: 0.0536 - mean_absolute_error: 0.1834 - val_loss: 0.0597 - val_mean_absolute_error: 0.1897\n",
      "Epoch 76/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0527 - mean_absolute_error: 0.1811 - val_loss: 0.0554 - val_mean_absolute_error: 0.1853\n",
      "Epoch 77/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0540 - mean_absolute_error: 0.1842 - val_loss: 0.0620 - val_mean_absolute_error: 0.1921\n",
      "Epoch 78/256\n",
      "6590/6590 [==============================] - 1s 77us/step - loss: 0.0525 - mean_absolute_error: 0.1809 - val_loss: 0.0544 - val_mean_absolute_error: 0.1833\n",
      "Epoch 79/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0519 - mean_absolute_error: 0.1795 - val_loss: 0.0525 - val_mean_absolute_error: 0.1767\n",
      "Epoch 80/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0507 - mean_absolute_error: 0.1768 - val_loss: 0.0505 - val_mean_absolute_error: 0.1746\n",
      "Epoch 81/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0508 - mean_absolute_error: 0.1758 - val_loss: 0.0526 - val_mean_absolute_error: 0.1717\n",
      "Epoch 82/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0492 - mean_absolute_error: 0.1723 - val_loss: 0.0480 - val_mean_absolute_error: 0.1666\n",
      "Epoch 83/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0486 - mean_absolute_error: 0.1706 - val_loss: 0.0494 - val_mean_absolute_error: 0.1683\n",
      "Epoch 84/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0489 - mean_absolute_error: 0.1720 - val_loss: 0.0503 - val_mean_absolute_error: 0.1710\n",
      "Epoch 85/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0481 - mean_absolute_error: 0.1696 - val_loss: 0.0463 - val_mean_absolute_error: 0.1618\n",
      "Epoch 86/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0471 - mean_absolute_error: 0.1669 - val_loss: 0.0478 - val_mean_absolute_error: 0.1628\n",
      "Epoch 87/256\n",
      "6590/6590 [==============================] - 1s 78us/step - loss: 0.0471 - mean_absolute_error: 0.1667 - val_loss: 0.0469 - val_mean_absolute_error: 0.1602\n",
      "Epoch 88/256\n",
      "6590/6590 [==============================] - 0s 76us/step - loss: 0.0471 - mean_absolute_error: 0.1664 - val_loss: 0.0468 - val_mean_absolute_error: 0.1631\n",
      "Epoch 89/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0465 - mean_absolute_error: 0.1651 - val_loss: 0.0480 - val_mean_absolute_error: 0.1584\n",
      "Epoch 90/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0497 - mean_absolute_error: 0.1680 - val_loss: 0.0478 - val_mean_absolute_error: 0.1642\n",
      "Epoch 91/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0475 - mean_absolute_error: 0.1680 - val_loss: 0.0545 - val_mean_absolute_error: 0.1713\n",
      "Epoch 92/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0465 - mean_absolute_error: 0.1646 - val_loss: 0.0457 - val_mean_absolute_error: 0.1562\n",
      "Epoch 93/256\n",
      "6590/6590 [==============================] - 1s 76us/step - loss: 0.0456 - mean_absolute_error: 0.1622 - val_loss: 0.0445 - val_mean_absolute_error: 0.1555\n",
      "Epoch 94/256\n",
      "6590/6590 [==============================] - 1s 82us/step - loss: 0.0448 - mean_absolute_error: 0.1608 - val_loss: 0.0429 - val_mean_absolute_error: 0.1510\n",
      "Epoch 95/256\n",
      "6590/6590 [==============================] - 1s 82us/step - loss: 0.0447 - mean_absolute_error: 0.1606 - val_loss: 0.0416 - val_mean_absolute_error: 0.1480\n",
      "Epoch 96/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0440 - mean_absolute_error: 0.1588 - val_loss: 0.0430 - val_mean_absolute_error: 0.1528\n",
      "Epoch 97/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0432 - mean_absolute_error: 0.1571 - val_loss: 0.0413 - val_mean_absolute_error: 0.1463\n",
      "Epoch 98/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0430 - mean_absolute_error: 0.1565 - val_loss: 0.0466 - val_mean_absolute_error: 0.1560\n",
      "Epoch 99/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0434 - mean_absolute_error: 0.1563 - val_loss: 0.0427 - val_mean_absolute_error: 0.1519\n",
      "Epoch 100/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0433 - mean_absolute_error: 0.1556 - val_loss: 0.0483 - val_mean_absolute_error: 0.1578\n",
      "Epoch 101/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0428 - mean_absolute_error: 0.1542 - val_loss: 0.0477 - val_mean_absolute_error: 0.1570\n",
      "Epoch 102/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0421 - mean_absolute_error: 0.1534 - val_loss: 0.0425 - val_mean_absolute_error: 0.1471\n",
      "Epoch 103/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0422 - mean_absolute_error: 0.1532 - val_loss: 0.0419 - val_mean_absolute_error: 0.1475\n",
      "Epoch 104/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0421 - mean_absolute_error: 0.1524 - val_loss: 0.0424 - val_mean_absolute_error: 0.1463\n",
      "Epoch 105/256\n",
      "6590/6590 [==============================] - 0s 66us/step - loss: 0.0423 - mean_absolute_error: 0.1532 - val_loss: 0.0462 - val_mean_absolute_error: 0.1519\n",
      "Epoch 106/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0422 - mean_absolute_error: 0.1534 - val_loss: 0.0421 - val_mean_absolute_error: 0.1467\n",
      "Epoch 107/256\n",
      "6590/6590 [==============================] - 1s 76us/step - loss: 0.0419 - mean_absolute_error: 0.1521 - val_loss: 0.0412 - val_mean_absolute_error: 0.1447\n",
      "Epoch 108/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0416 - mean_absolute_error: 0.1511 - val_loss: 0.0423 - val_mean_absolute_error: 0.1454\n",
      "Epoch 109/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0416 - mean_absolute_error: 0.1516 - val_loss: 0.0404 - val_mean_absolute_error: 0.1427\n",
      "Epoch 110/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0413 - mean_absolute_error: 0.1512 - val_loss: 0.0400 - val_mean_absolute_error: 0.1400\n",
      "Epoch 111/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0413 - mean_absolute_error: 0.1503 - val_loss: 0.0456 - val_mean_absolute_error: 0.1550\n",
      "Epoch 112/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0410 - mean_absolute_error: 0.1506 - val_loss: 0.0419 - val_mean_absolute_error: 0.1467\n",
      "Epoch 113/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0417 - mean_absolute_error: 0.1514 - val_loss: 0.0412 - val_mean_absolute_error: 0.1412\n",
      "Epoch 114/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0409 - mean_absolute_error: 0.1500 - val_loss: 0.0531 - val_mean_absolute_error: 0.1596\n",
      "Epoch 115/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0409 - mean_absolute_error: 0.1500 - val_loss: 0.0411 - val_mean_absolute_error: 0.1456\n",
      "Epoch 116/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0410 - mean_absolute_error: 0.1501 - val_loss: 0.0410 - val_mean_absolute_error: 0.1430\n",
      "Epoch 117/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0408 - mean_absolute_error: 0.1500 - val_loss: 0.0409 - val_mean_absolute_error: 0.1429\n",
      "Epoch 118/256\n",
      "6590/6590 [==============================] - 0s 67us/step - loss: 0.0408 - mean_absolute_error: 0.1498 - val_loss: 0.0419 - val_mean_absolute_error: 0.1429\n",
      "Epoch 119/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0412 - mean_absolute_error: 0.1493 - val_loss: 0.0408 - val_mean_absolute_error: 0.1435\n",
      "Epoch 120/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0408 - mean_absolute_error: 0.1489 - val_loss: 0.0417 - val_mean_absolute_error: 0.1454\n",
      "Epoch 121/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0402 - mean_absolute_error: 0.1473 - val_loss: 0.0422 - val_mean_absolute_error: 0.1470\n",
      "Epoch 122/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0406 - mean_absolute_error: 0.1489 - val_loss: 0.0407 - val_mean_absolute_error: 0.1443\n",
      "Epoch 123/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0413 - mean_absolute_error: 0.1505 - val_loss: 0.0418 - val_mean_absolute_error: 0.1448\n",
      "Epoch 124/256\n",
      "6590/6590 [==============================] - 1s 83us/step - loss: 0.0405 - mean_absolute_error: 0.1488 - val_loss: 0.0413 - val_mean_absolute_error: 0.1424\n",
      "Epoch 125/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0403 - mean_absolute_error: 0.1480 - val_loss: 0.0406 - val_mean_absolute_error: 0.1414\n",
      "Epoch 126/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0402 - mean_absolute_error: 0.1471 - val_loss: 0.0403 - val_mean_absolute_error: 0.1416\n",
      "Epoch 127/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0425 - mean_absolute_error: 0.1509 - val_loss: 0.0417 - val_mean_absolute_error: 0.1432\n",
      "Epoch 128/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0409 - mean_absolute_error: 0.1490 - val_loss: 0.0414 - val_mean_absolute_error: 0.1429\n",
      "Epoch 129/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0412 - mean_absolute_error: 0.1501 - val_loss: 0.0410 - val_mean_absolute_error: 0.1438\n",
      "Epoch 130/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0408 - mean_absolute_error: 0.1489 - val_loss: 0.0450 - val_mean_absolute_error: 0.1516\n",
      "Epoch 131/256\n",
      "6590/6590 [==============================] - 0s 76us/step - loss: 0.0407 - mean_absolute_error: 0.1490 - val_loss: 0.0410 - val_mean_absolute_error: 0.1427\n",
      "Epoch 132/256\n",
      "6590/6590 [==============================] - 1s 77us/step - loss: 0.0407 - mean_absolute_error: 0.1485 - val_loss: 0.0417 - val_mean_absolute_error: 0.1429\n",
      "Epoch 133/256\n",
      "6590/6590 [==============================] - 1s 78us/step - loss: 0.0404 - mean_absolute_error: 0.1475 - val_loss: 0.0423 - val_mean_absolute_error: 0.1436\n",
      "Epoch 134/256\n",
      "6590/6590 [==============================] - 1s 83us/step - loss: 0.0404 - mean_absolute_error: 0.1485 - val_loss: 0.0410 - val_mean_absolute_error: 0.1410\n",
      "Epoch 135/256\n",
      "6590/6590 [==============================] - 1s 80us/step - loss: 0.0403 - mean_absolute_error: 0.1485 - val_loss: 0.0420 - val_mean_absolute_error: 0.1442\n",
      "Epoch 136/256\n",
      "6590/6590 [==============================] - 1s 77us/step - loss: 0.0398 - mean_absolute_error: 0.1466 - val_loss: 0.0406 - val_mean_absolute_error: 0.1401\n",
      "Epoch 137/256\n",
      "6590/6590 [==============================] - 1s 83us/step - loss: 0.0396 - mean_absolute_error: 0.1462 - val_loss: 0.0411 - val_mean_absolute_error: 0.1403\n",
      "Epoch 138/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0398 - mean_absolute_error: 0.1469 - val_loss: 0.0409 - val_mean_absolute_error: 0.1421\n",
      "Epoch 139/256\n",
      "6590/6590 [==============================] - 1s 84us/step - loss: 0.0394 - mean_absolute_error: 0.1459 - val_loss: 0.0415 - val_mean_absolute_error: 0.1423\n",
      "Epoch 140/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0400 - mean_absolute_error: 0.1464 - val_loss: 0.0407 - val_mean_absolute_error: 0.1401\n",
      "Epoch 141/256\n",
      "6590/6590 [==============================] - 1s 78us/step - loss: 0.0395 - mean_absolute_error: 0.1454 - val_loss: 0.0422 - val_mean_absolute_error: 0.1434\n",
      "Epoch 142/256\n",
      "6590/6590 [==============================] - 1s 79us/step - loss: 0.0445 - mean_absolute_error: 0.1490 - val_loss: 0.0590 - val_mean_absolute_error: 0.1701\n",
      "Epoch 143/256\n",
      "6590/6590 [==============================] - 0s 76us/step - loss: 0.0417 - mean_absolute_error: 0.1521 - val_loss: 0.0526 - val_mean_absolute_error: 0.1608\n",
      "Epoch 144/256\n",
      "6590/6590 [==============================] - 1s 77us/step - loss: 0.0406 - mean_absolute_error: 0.1485 - val_loss: 0.0417 - val_mean_absolute_error: 0.1433\n",
      "Epoch 145/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0401 - mean_absolute_error: 0.1472 - val_loss: 0.0403 - val_mean_absolute_error: 0.1409\n",
      "Epoch 146/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0403 - mean_absolute_error: 0.1480 - val_loss: 0.0499 - val_mean_absolute_error: 0.1564\n",
      "Epoch 147/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0402 - mean_absolute_error: 0.1470 - val_loss: 0.0458 - val_mean_absolute_error: 0.1502\n",
      "Epoch 148/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0396 - mean_absolute_error: 0.1458 - val_loss: 0.0433 - val_mean_absolute_error: 0.1464\n",
      "Epoch 149/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0399 - mean_absolute_error: 0.1466 - val_loss: 0.0405 - val_mean_absolute_error: 0.1388\n",
      "Epoch 150/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0400 - mean_absolute_error: 0.1467 - val_loss: 0.0439 - val_mean_absolute_error: 0.1469\n",
      "Epoch 151/256\n",
      "6590/6590 [==============================] - 0s 68us/step - loss: 0.0390 - mean_absolute_error: 0.1447 - val_loss: 0.0432 - val_mean_absolute_error: 0.1457\n",
      "Epoch 152/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0391 - mean_absolute_error: 0.1448 - val_loss: 0.0410 - val_mean_absolute_error: 0.1409\n",
      "Epoch 153/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0394 - mean_absolute_error: 0.1454 - val_loss: 0.0412 - val_mean_absolute_error: 0.1420\n",
      "Epoch 154/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0401 - mean_absolute_error: 0.1461 - val_loss: 0.0403 - val_mean_absolute_error: 0.1405\n",
      "Epoch 155/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0394 - mean_absolute_error: 0.1457 - val_loss: 0.0414 - val_mean_absolute_error: 0.1442\n",
      "Epoch 156/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0391 - mean_absolute_error: 0.1445 - val_loss: 0.0415 - val_mean_absolute_error: 0.1410\n",
      "Epoch 157/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0392 - mean_absolute_error: 0.1450 - val_loss: 0.0412 - val_mean_absolute_error: 0.1401\n",
      "Epoch 158/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0398 - mean_absolute_error: 0.1460 - val_loss: 0.0410 - val_mean_absolute_error: 0.1415\n",
      "Epoch 159/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0398 - mean_absolute_error: 0.1459 - val_loss: 0.0406 - val_mean_absolute_error: 0.1405\n",
      "Epoch 160/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0391 - mean_absolute_error: 0.1447 - val_loss: 0.0400 - val_mean_absolute_error: 0.1386\n",
      "Epoch 161/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0392 - mean_absolute_error: 0.1448 - val_loss: 0.0415 - val_mean_absolute_error: 0.1425\n",
      "Epoch 162/256\n",
      "6590/6590 [==============================] - 0s 72us/step - loss: 0.0383 - mean_absolute_error: 0.1430 - val_loss: 0.0410 - val_mean_absolute_error: 0.1407\n",
      "Epoch 163/256\n",
      "6590/6590 [==============================] - 0s 71us/step - loss: 0.0391 - mean_absolute_error: 0.1441 - val_loss: 0.0420 - val_mean_absolute_error: 0.1451\n",
      "Epoch 164/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0393 - mean_absolute_error: 0.1452 - val_loss: 0.0406 - val_mean_absolute_error: 0.1383\n",
      "Epoch 165/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0392 - mean_absolute_error: 0.1441 - val_loss: 0.0424 - val_mean_absolute_error: 0.1426\n",
      "Epoch 166/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0394 - mean_absolute_error: 0.1450 - val_loss: 0.0412 - val_mean_absolute_error: 0.1412\n",
      "Epoch 167/256\n",
      "6590/6590 [==============================] - 0s 69us/step - loss: 0.0387 - mean_absolute_error: 0.1437 - val_loss: 0.0479 - val_mean_absolute_error: 0.1520\n",
      "Epoch 168/256\n",
      "6590/6590 [==============================] - 0s 70us/step - loss: 0.0392 - mean_absolute_error: 0.1449 - val_loss: 0.0443 - val_mean_absolute_error: 0.1475\n",
      "Epoch 169/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0391 - mean_absolute_error: 0.1440 - val_loss: 0.0411 - val_mean_absolute_error: 0.1415\n",
      "Epoch 170/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0390 - mean_absolute_error: 0.1439 - val_loss: 0.0411 - val_mean_absolute_error: 0.1403\n",
      "Epoch 171/256\n",
      "6590/6590 [==============================] - 0s 74us/step - loss: 0.0392 - mean_absolute_error: 0.1441 - val_loss: 0.0406 - val_mean_absolute_error: 0.1416\n",
      "Epoch 172/256\n",
      "6590/6590 [==============================] - 0s 73us/step - loss: 0.0388 - mean_absolute_error: 0.1439 - val_loss: 0.0399 - val_mean_absolute_error: 0.1390\n",
      "Epoch 173/256\n",
      "6590/6590 [==============================] - 0s 75us/step - loss: 0.0392 - mean_absolute_error: 0.1449 - val_loss: 0.0402 - val_mean_absolute_error: 0.1404\n",
      "Finished training; model reloaded with optimum weights.\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 256\n",
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.001,patience=64)\n",
    "check_point = ModelCheckpoint(WEIGHTS_FILE,monitor='val_loss',save_best_only=True,mode='max')\n",
    "history_object = model.fit(x=X_data, y=y_data,\n",
    "                           batch_size = BATCH_SIZE,\n",
    "                           epochs = NUM_EPOCHS,\n",
    "                           verbose = 1,\n",
    "                           callbacks = [early_stop,check_point],\n",
    "                           validation_split = VALIDATION_FRACTION)\n",
    "                           \n",
    "# reload model with best weights from training\n",
    "model = myNet()\n",
    "model.load_weights(WEIGHTS_FILE)\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['mean_absolute_error'])\n",
    "print(\"Finished training; model reloaded with optimum weights.\")\n",
    "model.save(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4VFX6wPHvm0kjlTRq6CCQUEIVBSliARSwi8oq1pXddde1rG1XLD931bX3XtcCoigqNqQoSu+EXgKEEAghCeltzu+PMwmTkAZkMgHez/PkSebOvXfeuQz3nXPuue8RYwxKKaVUTXy8HYBSSqnGT5OFUkqpWmmyUEopVStNFkoppWqlyUIppVStNFkopZSqlUeThYiMEpFNIrJVRO6t4vk7RGS9iKwRkZ9FpJ3bc6Uissr1M9OTcSqllKqZeOo+CxFxAJuBc4FkYClwlTFmvds6I4DFxpg8EZkMDDfGXOl6LscYE+KR4JRSSh0VT7YsBgJbjTHbjTFFwKfAePcVjDFzjTF5roeLgFgPxqOUUuoY+Xpw362B3W6Pk4HTa1j/RuA7t8eBIrIMKAEeN8Z8WXkDEbkFuAUgODi4X7du3Y4r4LyiUral5dA+KpjQQE8eGqWUahyWL19+wBgTU9t6njwjShXLquzzEpGJQH9gmNvitsaYFBHpCMwRkbXGmG0VdmbMG8AbAP379zfLli07roDX7cniwhcX8PzEfozq0eK49qWUUicCEdlZl/U82Q2VDLRxexwLpFReSUTOAR4AxhljCsuWG2NSXL+3A/OAPh6MFYBAPwcAhSWlnn4ppZQ6oXgyWSwFuohIBxHxByYAFUY1iUgf4HVsotjvtjxCRAJcf0cDg4H1eFignz0cBcWaLJRSyp3HuqGMMSUi8hfgB8ABvGOMSRSRR4BlxpiZwH+BEOAzEQHYZYwZB3QHXhcRJzahPe4+ispTDrcsnJ5+KaWUOqF49CquMWYWMKvSsgfd/j6nmu1+B3p6MraqBPhqy0KdnIqLi0lOTqagoMDboSgvCQwMJDY2Fj8/v2PaXof8uClrWRQUa8tCnVySk5MJDQ2lffv2uFrx6hRijCE9PZ3k5GQ6dOhwTPvQch9u/Bw+OHxEWxbqpFNQUEBUVJQmilOUiBAVFXVcLUtNFpUE+vpoy0KdlDRRnNqO999fk0UlgX4OHTqrlFKVaLKoJEBbFkrVu8zMTF555ZVj2nbMmDFkZmbWuM6DDz7I7Nmzj2n/lbVv354DBw7Uy74q+/LLL3nkkUc8su8yd911F3PmzKn3/WqyqCTQz0GBtiyUqlc1JYvS0pr/v82aNYumTZvWuM4jjzzCOedUObiyUXnyySf505/+5NHXuO2223j88cfrfb+aLCoJ8HNQqBe4lapX9957L9u2bSMhIYG7776befPmMWLECK6++mp69rSj5C+66CL69etHfHw8b7zxRvm2Zd/0k5KS6N69OzfffDPx8fGcd9555OfnAzBp0iSmT59evv6UKVPo27cvPXv2ZOPGjQCkpaVx7rnn0rdvX/74xz/Srl27WlsQzzzzDD169KBHjx4899xzAOTm5nLBBRfQu3dvevTowdSpU8vfY1xcHL169eKuu+46Yl+bN28mICCA6Ojo8pgnT57MiBEj6NixI/Pnz+eGG26ge/fuTJo0qXy7yZMn079/f+Lj45kyZUr58uXLlzNs2DD69evH+eefz969ewFo164d6enppKam1v0fqA506GwlgX7aDaVObg9/ncj6lEP1us+4VmFMGRtf7fOPP/4469atY9WqVQDMmzePJUuWsG7duvKhnO+88w6RkZHk5+czYMAALr30UqKioirsZ8uWLXzyySe8+eabXHHFFXz++edMnDjxiNeLjo5mxYoVvPLKKzz11FO89dZbPPzww5x99tncd999fP/99xUSUlWWL1/Ou+++y+LFizHGcPrppzNs2DC2b99Oq1at+PbbbwHIysri4MGDzJgxg40bNyIiVXab/fbbb/Tt27fCsoyMDObMmcPMmTMZO3Ysv/32G2+99RYDBgxg1apVJCQk8NhjjxEZGUlpaSkjR45kzZo1dO/endtuu42vvvqKmJgYpk6dygMPPMA777wDQN++ffntt9+49NJLa3yPR0NbFpUE+uoFbqUawsCBAyuM+X/hhRfo3bs3gwYNYvfu3WzZsuWIbTp06EBCQgIA/fr1Iykpqcp9X3LJJUess2DBAiZMmADAqFGjiIiIqDG+BQsWcPHFFxMcHExISAiXXHIJv/76Kz179mT27Nncc889/Prrr4SHhxMWFkZgYCA33XQTX3zxBUFBQUfsb+/evcTEVCzuOnbsWESEnj170rx5c3r27ImPjw/x8fHlcU+bNo2+ffvSp08fEhMTWb9+PZs2bWLdunWce+65JCQk8H//938kJyeX77dZs2akpBxRiu+4aMuikgA/H3JySrwdhlIeU1MLoCEFBweX/z1v3jxmz57NwoULCQoKYvjw4VXeExAQEFD+t8PhKO+Gqm49h8NBSYn9/3y0E71Vt/5pp53G8uXLmTVrFvfddx/nnXceDz74IEuWLOHnn3/m008/5aWXXjriInOTJk3IysqqMk4fH58K783Hx4eSkhJ27NjBU089xdKlS4mIiGDSpEkUFBRgjCE+Pp6FCxdWGWNBQQFNmjQ5qvdbG21ZVBLo69Cb8pSqZ6GhoWRnZ1f7fFZWFhEREQQFBbFx40YWLVpU7zEMGTKEadOmAfDjjz+SkZFR4/pDhw7lyy+/JC8vj9zcXGbMmMFZZ51FSkoKQUFBTJw4kbvuuosVK1aQk5NDVlYWY8aM4bnnnivvbnPXvXt3tm7delQxHzp0iODgYMLDw9m3bx/ffWen/OnatStpaWnlyaK4uJjExMTy7TZv3kyPHj2O6rVqoy2LSgL9fHQ0lFL1LCoqisGDB9OjRw9Gjx7NBRdcUOH5UaNG8dprr9GrVy+6du3KoEGD6j2GKVOmcNVVVzF16lSGDRtGy5YtCQ0NrXb9vn37MmnSJAYOHAjATTfdRJ8+ffjhhx+4++678fHxwc/Pj1dffZXs7GzGjx9f/q3/2WefPWJ/Q4cO5c4778QYU+cb5Hr37k2fPn2Ij4+nY8eODB48GAB/f3+mT5/OX//6V7KysigpKeH2228nPj6e4uJitm7dSv/+/Y/hKFXPY3NwN7T6mPwI4N7P1zBn436WPND4h+EpVVcbNmyge/fu3g7DqwoLC3E4HPj6+rJw4UImT55cZQvAk/72t78xduxYjw7znTFjBitWrODRRx894rmqPgcistwYU2tm0ZZFJYF+2g2l1Mlo165dXHHFFTidTvz9/XnzzTcbPIb777+fxYsXe/Q1SkpKuPPOO+t9v5osKgkOcJBbVIrTafDx0Vo6Sp0sunTpwsqVK70aQ/PmzRk3bpxHX+Pyyy/3yH71AnclUcEBlDoNmfnF3g5FKaUaDU0WlUSH2uFrB3IKa1lTKaVOHZosKokO8QfgQLYmC6WUKqPJopKYENuySNOWhVJKldNkUUl0SFk3VJGXI1Hq1BYSEgJASkoKl112WZXrDB8+nNqGzD/33HPk5eWVP65LyfO6eOihh3jqqaeOez8nCk0WlYQ38cPXR/SahVKNRKtWrcoryh6LysmiLiXP1ZE0WVTi4yNEhfjrNQul6tE999xTYT6Lhx56iKeffpqcnBxGjhxZXk78q6++OmLbpKSk8tIV+fn5TJgwgV69enHllVdWqA1VVSnvF154gZSUFEaMGMGIESOAipMbVVWCvKZS6NVZtWoVgwYNolevXlx88cXlpUReeOGF8rLlZUUM58+fT0JCAgkJCfTp06fGMiiNid5nUYXokABtWaiT13f3Qura+t1ni54wuvoJdyZMmMDtt99ePvHPtGnT+P777wkMDGTGjBmEhYVx4MABBg0axLhx46oth/Hqq68SFBTEmjVrWLNmTYWS31WV8v7rX//KM888w9y5c8vnkShTXQnyiIiIOpdCL3Pttdfy4osvMmzYMB588EEefvhhnnvuOR5//HF27NhBQEBAedfXU089xcsvv8zgwYPJyckhMDCwzofZm7RlUQWbLPSahVL1pU+fPuzfv5+UlBRWr15NREQEbdu2xRjD/fffT69evTjnnHPYs2cP+/btq3Y/v/zyS/lJu1evXvTq1av8uapKedekuhLkUPdS6GCLIGZmZjJs2DAArrvuOn755ZfyGK+55hr+97//4etrv5sPHjyYO+64gxdeeIHMzMzy5Y3diRFlA4sOCWDzvhOjaajUUauhBeBJl112GdOnTyc1NbW8S+ajjz4iLS2N5cuX4+fnR/v27assTe6uqlZHdaW8a1JTXby6lkKvzbfffssvv/zCzJkzefTRR0lMTOTee+/lggsuYNasWQwaNIjZs2fTrVu3Y9p/Q9KWRRWiQ/1Jzyk66vr3SqnqTZgwgU8//ZTp06eXj27KysqiWbNm+Pn5MXfuXHbu3FnjPoYOHcpHH30EwLp161izZg1QfSlvqL48enUlyI9WeHg4ERER5a2SDz/8kGHDhuF0Otm9ezcjRozgySefJDMzk5ycHLZt20bPnj2555576N+/f/m0r42dtiyqEBMSQFGpk0P5JYQH+Xk7HKVOCvHx8WRnZ9O6dWtatmwJwDXXXMPYsWPp378/CQkJtX7Dnjx5Mtdffz29evUiISGhvHx4daW8AW655RZGjx5Ny5YtmTt3bvny6kqQ19TlVJ3333+fW2+9lby8PDp27Mi7775LaWkpEydOJCsrC2MMf//732natCn/+te/mDt3Lg6Hg7i4OEaPHn3Ur+cNWqK8Cl+u3MPtU1cx+45hdG4WUi/7VMqbtES5guMrUa7dUFU4fGOejohSSinQZFGl6FBXfShNFkopBWiyqFJ5y0JvzFMnkZOly1kdm+P999dkUYWIIH98ROtDqZNHYGAg6enpmjBOUcYY0tPTj+sGQB0NVQWHjxAZrHdxq5NHbGwsycnJpKWleTsU5SWBgYHExsYe8/aaLKoRHeLPxtRsikud+Dm0AaZObH5+fnTo0MHbYagTmJ4Fq3HlgDas2p3JzR8s47ZPVhL34PesTc7ydlhKKeUVHk0WIjJKRDaJyFYRubeK5+8QkfUiskZEfhaRdm7PXSciW1w/13kyzqpcP7gD/3dRD+ZvTmPexv0Ulzr5fEVyQ4ehlFKNgseShYg4gJeB0UAccJWIxFVabSXQ3xjTC5gOPOnaNhKYApwODASmiEiEp2KtzsRB7fjp70P57b6zGd61GT8kpuJ06gVCpdSpx5Mti4HAVmPMdmNMEfApMN59BWPMXGNM2awki4Cyqy/nAz8ZYw4aYzKAn4BRHoy1Wp2bhRIW6MeYni3Ym1XAquTjn2FLKaVONJ5MFq2B3W6Pk13LqnMjUFb9q07bisgtIrJMRJZ5epTHyO7N8XMI363dizFGhyAqpU4pnhwNVdXsJVWeYUVkItAfGHY02xpj3gDeAFsb6tjCrJuwQD+GdI7m48W7mLp0N8EBvtw6rBMTBrYhwNfhyZdWSimv82TLIhlo4/Y4FkipvJKInAM8AIwzxhQezbYNbdLgDnSICWZMz5bERjRhysxErnlzMdkFxd4OTSmlPMpjVWdFxBfYDIwE9gBLgauNMYlu6/TBXtgeZYzZ4rY8ElgOlM2ZuALoZ4w5WN3r1WfV2bowxjBzdQp3TltNj9bhXNovluyCYuZtSsMhwoNj4+jeMqzB4lFKqWNR16qzHuuGMsaUiMhfgB8AB/COMSZRRB4BlhljZgL/BUKAz1yzX+0yxowzxhwUkUexCQbgkZoShTeICOMTWhPg6+Bvn67kX1+uAyCuZRj7swsY99ICrj2jPVcOaMMnS3bxxYo9dG0eyvBuMVx3RnuCA3wpKnGy71ABaTmFpGUX4u/rw/DTYhARNqYeYvXuTA7kFDG2VyvaRgV5+R0rpU5lOp9FPcgvKiW7sBhfHx8ig/3JyC3isVkbmLFyD6VOgwiMim/Bnsx81iRnER0SQOdmwazYmUlRqbPCvs7sFEXL8CYV7ukI9PPhtrO7cG5cczrHhODjc+QlndSsArbsz6Zri1CahQZSXOrku3WpzNu0nwt6tuTsbs3Kp6PMLyol0M+nwvSUJaVOvlqVwsvztrIrPQ+HjxAR5E9sRBOu6N+GcQmtKCp1si45i9+3pdM0yI8ercMJCfAlyN9Bq6ZNCPTTazdKnWjq2rLQZOFByRl5zFq7lzM6RtMzNhyAFbsyePrHTWTmFXNmpyg6NwuhWWggMaEBrNqdyRPfbaSgpJQbh3Tk6oFt8fGBh2YmMnvDfgBCAnzpFRtO0yA/8opKCW/iR0mp4YfEVEpc94D4O3wwGIpLDQG+PhSWOOnaPJRWTQPZd6iQDamH6BXblBcn9KFtVBCrdmdy3xdr2bD3EHEtwxjeNYZSYziYU8TaPVlsTK04JaWPQFW3m7QIC6RtVBBDu0Rz5YC2rN97iE2ph7iwVyuiQvz5bm0qBcWl9IwNJ8DXga+P0D46uMI+svKLyS0soajEydKkg2xMzcbhI7SLCmJc71aEBurMhUrVJ00WJ6gDOYUUljhp3bRJ+TJjDNsP5LJyVyard2eyOjmTvKJSmvg5yMwvIq+wlHEJrRjRtRmb92WTnluE02kY2CGSIV2i+WxZMt+t20t2QQkhAb7Etwpj6tLdFJcaggMcHMgpokVYIP+6MI4xPVtUaHEYY1iw9QDLkjIICfClfXQwZ3aKIrewhA2p2RQUl5JbWMLug/nsOpjHtrQcVu2ueC+Kn0MIDfTjYO6RVXyHdI7mhiHt8XP4MGttKtOX27jKBPr5YAwUljgJ8nfQIiyQvKJSzuwUxSV9Y+nfPkJbNEodB00WqkbJGXm8NGcrItA2MpiJg9rW27f2zfuy+WZ1CnGtwjmteQgfLNzJ/uwCrh7YjlZNA0lMOYTTGPZmFfDGL9vLk4i/w4crBsTSs7VthfVu05SuzUMREVbvzmTqst0cyi9GRJi3cT/ZhSX4OYSercPp3z6S8QmtiG8VXi/vQalThSYLdULIKSxh3Z4sBOgQE0yz0LrV2y8oLmXBlgMs3XmQ5UkZrEnOwmkMfxrRmZAAB5tSczg3rjnxrcL4bt1emocFMq53qwqtJqWUJgt1isnKK+bBmev4apW9HSc0wJfswpIK61zeL5ZHL+qh3VZKufH60FmlGlJ4kB/PT+jDzWd1JCrEn5iQAOZs3E9Sei7nxbXgixXJvDBnK0npubx5bX+aBvl7O2SlTijaslCnjG/WpHDH1NW0jQriP5f0pEVYIP+Yvoa0nEL+dWEcw06LqbC+MYaiUqeWc1EnNe2GUqoKC7elc9snKziQU4SfQwjwdRAV4s/O9DziW4UxpEs0fxzaichgf/4+dRVLkw7y7V/PIryJDtlVJyfthlKqCmd0iuLXf5zNp0t3sXlfDn8e0YmY0AD+t2gXPyam8vavO1i8/SB/GNSOGSv3APDk9xt57OKeXo5cKe/SloVSbr5fl8rkj5ZjDPRsHU6/dhG893sSn916BgPaR3o7PKXqXV1bFjoHt1JuRvVowcPj4okOCeCpy3tz9/ldad20CZPeWcJny3brPCbqlKUtC6WqYIwpvydjT2Y+d0xdxeIdB7nz3NO4bWQXL0enVP3RloVSx8H95r3WTZvw8c2DGJ/Qimdnb2bhtnQvRqaUd2iyUKoOHD7Cvy/uSfvoYP766UrmbdqvXVLqlKLJQqk6Cg7w5dVr+uHv8GHSu0u56s1FFJU4a99QqZOAJguljkLXFqHMvWs4/7ygO4u2H+SDhUneDkmpBqHJQqmj5O/rw01ndWRE1xien72FtOzC2jdS6gSnyUKpY/SvC+MoKCnl/hlrKSguJS27kFfnbSOjink7lDrR6R3cSh2jjjEh3Du6O49+s57LXvudPRn5ZOQV8/OGffzvptO1uq06qWjLQqnjcOOQDrw2sS/b03JpGxnEA2O6s2xnBndPX6OjpdRJRVsWSh2nUT1aMrhzNMH+vvj4CMVOJ09+v4mENk25cUiHarfLLSyhpNQQ1sRXJ2VSjZ4mC6XqgfuUtJOHdWLlrkz+M2sD8a3COL1D5BHJ4KGZibz3exIA4xNa8fyEPg0ZrlJHTZOFUvVMRHjqst6MeeFXJryxiCZ+DtpGBtEhOphJg9uTkVvEe78nMa53K/wcPny+IpmLElozolszb4euVLU0WSjlAeFBfkyffAY/rd9H0oE8dh3MZcWuDL5PTCXA14feseE8fUVvjIGVuzJ4+OtEzuwcpRMtqUZLk4VSHtIyvAnXntG+/HF+USnP/byZHxP38eyVCfg57PiSB8fGMendpfz3+03888I4L0WrVM00WSjVQJr4O7hvdHfuG929wvLhXZtx7RnteGvBDtpHBzNxUDsvRahU9TRZKNUIPHhhHMkZ+Tz41ToO5hYxeXin8paHUo2BJgulGgFfhw8vXtWH+2es5ZmfNjN9eTKnNQ/h7G7NuWpgGx1aq7xOk4VSjURwgC/PT+jD6B4tmLYsme1puczesJa1e7J4ZHy8tjSUV2myUKqRGdWjJaN6tMTpNDz14yZembeNXQdzeeXqfoQH+dW+A6U8QL+qKNVI+fgI/xjVjf9e1oslOw5y8au/8fnyZNJzCrWUiGpw2rJQqpG7vH8b2kYGcce01dz52WoAfH2ETjEhXNK3NVcOaEPTIH8vR6lOdnKyfEPp37+/WbZsmbfDUMpjnE7Dmj1ZLEs6yMHcIhZtT2fFrkyiQwJ48rKenN2tubdDVCcgEVlujOlf23raslDqBOHjIyS0aUpCm6bly9btyeKuz1Zzw3vLGNA+gnEJrYmNaEKn6BDaRgUBsCs9j90ZeRSXOhncOVovlKtj4tGWhYiMAp4HHMBbxpjHKz0/FHgO6AVMMMZMd3uuFFjrerjLGDOuptfSloU6VRWWlPLB7zv5ZMkuth/ILV8+sEMkhcWlrE7OKl/WvWUYj13cg75tI7wRqtdlFxTj5/DRuUbc1LVl4bFkISIOYDNwLpAMLAWuMsasd1unPRAG3AXMrJQscowxIXV9PU0W6lRnjGHXwTwO5BSyZEcGny3fTYCvg0v7tia+VTj7swv4z6yNpB4qYNhpMfRsHc6aPVmEN/GjV+twxiW0onlYIGBbLN+s2UtcqzDG9mrpsfs80nMKiQz2b5D7SA4VFDP6uV9pFhbA57eeiY+P3rsCjaMbaiCw1Riz3RXQp8B4oDxZGGOSXM85PRiHUqcEEaFdVDDtooLp1y6SycM7HbHOyO7Nef/3JN5ZsIMFWw/QpVkI2/bn8PXqFJ78YSMD2keyMz2PPZn55dv8mJjKGZ2iKC5xUlxqcBqDn8OHsCZ+NAsNoEfrcCKDq77AvjTpIE//uIk/DuvEiK4Vq+qu25PFRS//xvk9WvDsFQks2p5OalYB4/u08khBxf/7Zj17MvPZk5nPjJV7uLRfbL2/xsnMky2Ly4BRxpibXI//AJxujPlLFeu+B3xTqWVRAqwCSoDHjTFfVrHdLcAtAG3btu23c+dOT7wVpU46RSVOSp2GJv72pLwzPZd3f0ti0fZ0ujQPZWD7CC7o1YqPF+/k2dlbKHXWfJ7o2jyUHq3DGdQxkkv7xiIC7/6WxL9nbcBgWz33j+nOdWe2L79mcu07S1iyI52CYifNQgPYn10IQIfoYEb1aEFBcSndW4QxvGsMzVwtnuJSJxl5Rfj6+FSboKoyd9N+rn93KbcO68TC7emkZuUz587hBAfoZdvG0A11OXB+pWQx0BhzWxXrvseRyaKVMSZFRDoCc4CRxpht1b2edkMp5RlZ+cUUlpTi7/ApP9EXlzrJyi9mb1YBy3dmsGTHQRJTDnEgp5Dz4poT4Ofg69UpnBfXnEcv6sE/v1zHT+v30TwsgGtOb0fHmGD+8vFK7h/TjYggf16Zt40/DGpHh+hgHpu1gaQDufj7+pBXVIoInNu9OT1ah/Phop2kuZLK+fHNeX5Cn1qvPxSVODnv2fk4fIRZfzuLdXsOcemrv9O3bVPuH9OdxJRDpGTlc9WAtrSPDvb48WxsGkOyOAN4yBhzvuvxfQDGmP9Use57VEoWR/M8aLJQytuMMbxT1powhrvP78atwzoiIjidhrmb9vPBwp3M35wGQIuwQObdPfyIk737OWljajbfrEnho8W7yMwr5qwu0Zwb15yUzAJe/2Ub/dpGcNNZHQgN9GPuxv0Y4PrB7YkOCWB7Wi6dmgXzv0W7ePSb9bx7/YDyrrCvVu1hysxEMvOKASi7fHFp31juHtUVQfh5wz72ZxcSHODLtWe0O2lHkTWGZOGLvcA9EtiDvcB9tTEmsYp138MtGYhIBJBnjCkUkWhgITDe/eJ4ZZoslGoc1iZnUeJ00qeaEVfb03KYvjyZwZ2jGdw5uk77zCsqIT2niDaRQeXLvlmTwl2fraag2F7y9Hf4YDAYAz4iFJXa7q384lIS2jTlgxsGVriQnp5TyPeJqfRrF0FkkD+v/7KdDxYm4efwoajESYlb19voHi144ao++Dl8SDqQy4/rU/kxcR9r9mTRKSaEIZ2jmDy8M5HB/qRlF/L+70l8vSYFAdpEBnHneV0rDHl2l1tYQnGp85hvrDTGkF1YQljgsZWC8XqycAUxBjs01gG8Y4x5TEQeAZYZY2aKyABgBhABFACpxph4ETkTeB1wYkuSPGeMebum19JkodSpp6C4lE2p2RzMLWJAh0gO5Rfz/sIkjIHOzUL4enUKy5IymPHnM+nWIqzW/e04kMvLc7cSGezPpX1j6RgTzAcLd/LoN+tp3bQJJU4n+w7ZbrD4VmH0bxfB9gO5/L4tnWB/B+2igklMycIAw06LITTQj0Xb00nLLqR7yzAKS0q5tG8sfxreiaJSJx8u3MlLc7eSW1jChAFtKSgu5fvEVM7t3pzrzmzPi3O2sGlfNpf3a8PwrjEE+fuSV1RCdkEJUSH+7MnI54U5WwkL9OXDG08/pmPYKJJFQ9JkoZSqSqnT4DjOYbLTlu3mx8RUwpv4E9cqjPPimldo5Wzel81TP2wiK7+YQR2jGJ/Qio4xduR/dkExr8zbxoa9h8grKmXJjoOMim/BupRKg0b4AAAds0lEQVQskjPyOatLNLERTfhsWTJ+Dh+GdIlm7sb9lDgNwf4OesaGs2j7wWpji41owl9GdObKAcdWyl6ThVJKNTLGGJ7+cTMvzd1KfKsw7h3djbO6xAC2W8zf14fQQD82pWbz7ZoUrj69HS3CA0k6kMuW/TnkFZUQ7O9LSKAv6TlF+AicE9f8uK6naLKoq9Ji2LcOwlpDSLPa11dKqeO0Kz2P2IgmjeLGwLomi5Pz8v7RyM+EN4bD+q+8HYlS6hTRNiqoUSSKo6HJwq+J/V2cX/N6Sil1CtNkoclCKaVqpcnCxwG+gVCc5+1IlFKq0dJkAbZ1oclCKaWqpckCwC9Ik4VSStVAkwW4WhZ6zUIppaqjyQI0WSilVC3qlCxE5G8iEibW2yKyQkTO83RwDUa7oZRSqkZ1bVncYIw5BJwHxADXA4/XvMkJRFsWSilVo7omi7JbDccA7xpjVrstO/Fpy0IppWpU12SxXER+xCaLH0QkFFs+/OSgLQullKpRXSegvRFIALYbY/JEJBLbFXVy8AuCIm1ZKKVUderasjgD2GSMyRSRicA/gSzPhdXAtBtKKaVqVNdk8SqQJyK9gX8AO4EPPBZVQ9NuKKWUqlFdk0WJsRNfjAeeN8Y8D4R6LqwG5hcEpYXgLPV2JEop1SjVNVlki8h9wB+Ab0XEARzb7OCNkVaeVUqpGtU1WVwJFGLvt0gFWgP/9VhUDU2ThVJK1ahOycKVID4CwkXkQqDAGHMSXbNwTbyuF7mVUqpKdS33cQWwBLgcuAJYLCKXeTKwBlXestBkoZRSVanrfRYPAAOMMfsBRCQGmA1M91RgDUpbFkopVaO6XrPwKUsULulHsW3j51+WLPSahVJKVaWuLYvvReQH4BPX4yuBWZ4JyQv8NFkopVRN6pQsjDF3i8ilwGBsAcE3jDEzPBpZQ9JrFkopVaO6tiwwxnwOfO7BWLxHh84qpVSNakwWIpINmKqeAowxJswjUTU0vcCtlFI1qjFZGGNOnpIeNSlrWWjlWaWUqtLJM6LpeOgFbqWUqpEmCwCHH/j4ajeUUkpVQ5NFGb8gbVkopVQ1NFmU0QmQlFKqWposyugESEopVS1NFmW0ZaGUUtXyaLIQkVEisklEtorIvVU8P1REVohISeUqtiJynYhscf1c58k4AW1ZKKVUDTyWLFyz6b0MjAbigKtEJK7SaruAScDHlbaNBKYApwMDgSkiEuGpWAFXstCWhVJKVcWTLYuBwFZjzHZjTBHwKXYO73LGmCRjzBrAWWnb84GfjDEHjTEZwE/AKA/Gqt1QSilVA08mi9bAbrfHya5l9batiNwiIstEZFlaWtoxBwpoN5RSStXAk8lCqlhWVZ2pY97WGPOGMaa/MaZ/TEzMUQV3BL3PQimlquXJZJEMtHF7HAukNMC2x0avWSilVLU8mSyWAl1EpIOI+AMTgJl13PYH4DwRiXBd2D7PtcxztBtKKaWq5bFkYYwpAf6CPclvAKYZYxJF5BERGQcgIgNEJBm4HHhdRBJd2x4EHsUmnKXAI65lnuMfbFsWpq49ZUopdeqo8+RHx8IYM4tK068aYx50+3sptoupqm3fAd7xZHwVuE+AVDYnt1JKKUDv4D5My5QrpVS1NFmU0Xm4lVKqWposymjLQimlqqXJoox/sP1dmO3dOJRSqhHSZFEmKMr+zvfsoCullDoRabIoU5Ys8tK9G4dSSjVCmizKBEXa35oslFLqCJosygQ2BXFoslBKqSposigjYruicg94OxKllGp0NFm4C4rSloVSSlVBk4W7oCjI09FQSilVmSYLd8HaslBKqaposnCn3VBKKVUlTRbugqLsTXnOylOCK6XUqU2ThbugKDBOKMj0diRKKdWoaLJwFxRtf2tXlFJKVaDJwp3exa2UUlXSZOFO60MppVSVNFm402ShlFJV0mThrixZaMkPpZSqQJOFO/8gO2OetiyUUqoCTRaVackPpZQ6giaLyoIiK7Ys8g5CSdHx7TNlFXwwHrL2HN9+lFLKSzRZVOZe8mPXYng2Hp7sAFMnQsbOiusWZEFxQc37c5bC13+F7fNgwTMeCVkppTxNk0VlQdGQsx92/g4fXwGhLaDXFbD9F3j7PEhda9fLTYcX+8F/O8G062DzD3BgC3x4MTzXE+b+B/ZvgKVvw97VEN0VVnwIh/bCnuV2/cJsOJQC2+ZAykrIz6hbjAWHYOEr8NY5MO/x42/5HCtjYPOPMPffUFrsmf1r6RWlGgUxxng7hnrRv39/s2zZsuPf0Q8PwMKX7N8hzeHGHyGivT3x/+9Se4Kf+AUsewfWToNeV9oTf55rBFVAOLTqDTt+ObzPDkNh7As2uUR2hPQtricEcDv+Pr7Q4zI4606IOc0uy9wNpUW2xdOkKWz9Gb6cDDn7IKozpG+FyE7QrDv4BtiTdlGObR2VtXqiu0CLntCil/0dHmsneyrjdMK8f8P6meAfDAGhEBhu31u3Cw6vm7zMvm6HoZC8FH57AbbPtc/1vgrGPg+JX8KeZTYJth8CPa+w1XydTrt872rI2m1jaXemTZKF2RB3EfgF2n0V5sDaz+wxTtsEva+EM/4CMV0Px1yUaxN3m9Mrvhel1FERkeXGmP61rqfJopLM3bDxWwiOhnaDIazl4eeykuG9C+0JszgPhtwB50yx3+w3fwep62DAjbY1krETdi2CtI3QbxJEtIOv/gyrPoZBf4Iu59rWS5NIaB5nT5g7foUVH4CPAyZ9Y0/I3955+PUDw23XV0w3GPcStBkAm76D31+E/EwoKQCHnz3hB0WBXxPbDZa2ySaVssTUJAI6nwMJV4MjABa/Bhtm2iTg8Lcn66zdcGiPXdbjMjiw+XASLUtyTSJh6N22RfTLkzZRFmaBf4h9/cyddt3IDlBSaPcHID62Bpe7kBbQ5RwoyoMtP0FRNjSLh5a9IHGGfW9dzoeOw6A4Hxa/Drn7ocelNhEHhBz5b5mdav9NSgogdgCENj+6z8KqT2DnbzD+pdrXVeoEpcnCUw6lwPtjbRfJrQvscNu6Kim0iaZp2+rXyUqGd0bZpFB4yJ4ge1xiu8YykmwSG/J3mwiORmEO7F8PqWtgz0rY8LU9sQMgcP5jNomVfUsvLYFlb8OCZyF7r1024GbofqFtNcV0g+7jbGvAGNsi258IZ94GnUba/aSus4l33zrA2PXbD7Ettt1LbEujVR+b0H592iY1X39oe6ZNurED7H5yD8DSt2DJm4dbcO2GQGw/myjD28CQ26H31TaeQykw7VqbbMuExcKfF9lWU129cqZ9T3dusl8AlDoJabLwpJJC2zV0NCeeo3FgK7x3AbRKgCs+sN1L9a0oD3bMt/uO7Gi72qpijG1VlBTab/ne5HTaFkdxAYQ0s4lkx6/w04OQsgLiL4HL37WPf38JRtxvW4c5++CzSXD6rTD68Yr7TNtku+5a9ICcNPjmdhh2DwSGwfO97ToXvw69JzT421X1qDDHtoCbtvF2JI1OXZOFb0MEc9LxDfDMCbxMdGe4fa3tUvJUf7x/EHQdXft6IhWvFXiTj4/tigsMP7ysw1lw8xz48Z+w8GU4+5+w+lM47XwYetfh9XbcAEtety2j9kNsYpj7GKx4H3ybwC1zYf6TsPEb283V+Ry7nV8QbJuryeJEN+8/sOoj20r05P/dk5gmi8bK19/bEZw4ROCMP9trL59dZ1sSCddUXOecKbB1Nrw/znbrbf7BXnfqfwOs/8ouz0mFqC6w7Wc7si2mux04sH2ebWHphfQT14HNtmWx4xd7vVAdNR06q04OYa3siKrUtfbiepfzKj4fGA5//AUSrrIjrdqeAZMXwgVPw6Vv2QQT3RVu+MFeqM/aBd3GQKcRNons3+Cd96XqR+Zu+3vD196N4wSmyUKdPAb9yf7udWXVLbMmTWH8y/CPHXDNtMPDkzsOh+u+homf22G+A2+2y7tdAB1H2L/LhgjXt/Rt9t4b5TnG2NF9AJtm2QEV6qhpslAnj9h+cPU0e4G6JmWTXLnrcNbhi59D77b30rTuZ5c1i7P3lKRtqt94jYEPLrJ3+DdmnrjhsiHlZ9h7j1r3g9w0OxJPHTWPJgsRGSUim0Rkq4jcW8XzASIy1fX8YhFp71reXkTyRWSV6+c1T8apTiKnnW9bEMfDLxA6jzz8+NK3AQPvjoG9a+yy7fNg3hP2hH+sUtfY7q6dCxvvt92cNHi8nb1T/0RV1qrof4O9j2jjN96N5wTlsWQhIg7gZWA0EAdcJSJxlVa7EcgwxnQGngWecHtumzEmwfVzq6fiVKpWzePg+u/ANxDevxAWPAcfXW7vet/527Hvd9P39ndRtr0HpjHauxqKc4/vfXpb2fWKZnH2jv9dC70bzwnKky2LgcBWY8x2Y0wR8CkwvtI644H3XX9PB0aK6JAT1QhFdYIbvrN3rc+eYk88QVF2uC7Ye0A2fA2f32RvrKyLTbMg3HWD5q5Fnon7eJUlsRP5An9Zy6JpW1tmZl+ivem0TMEhWxla1ciTyaI1sNvtcbJrWZXrGGNKgCzANV0dHURkpYjMF5GzqnoBEblFRJaJyLK0tLT6jV6pypq2hRu+hxH/hGu/hAE32XIraz6D18+ylYnXfmYLK9bmUArsXQX9r3fd0b7Y8/Efi7IkkXYCJ4vM3fZemqAoWxutpAAObjv8/G/PwZsj7HBpVS1PJouqWgiVO3irW2cv0NYY0we4A/hYRMKOWNGYN4wx/Y0x/WNiYo47YKVqFdoCht1t62sNuMneOPnFTfYi6iVv2rvEV39qRzntXgprp9ub/MBVpfcH2/r46s92Wdcx0HaQLYd/tIyxpWdeHQw/P2qLK9a3spZF5i5bv+xElLXrcPHMFj3tsrLq0WCPvXHakjONRe4B+6Wj7LPTCHjyprxkwP3e+lggpZp1kkXEFwgHDhpbg6QQwBizXES2AacBDVTPQ6k6CGkG5zxkv7mOuM/ey9FhGCx/35a3T9+GLbgYYWtgFRyy9bCCosFZYvvPY7pCm0H2xsBDKfZ+kZrkHbTXD7qPhT0r7E1mUZ3h16fsyfDsfx65TUEWBIQd/U2FZUUoI9rbumRpmyC21qoQjU9W8uGRbtGngY+fHVzQ8zL7HlNW2utRa6bBsH/Y8jfetuxdmP+E/TIy9G5vRwN4tmWxFOgiIh1ExB+YAMystM5M4DrX35cBc4wxRkRiXBfIEZGOQBdguwdjVerYnPFnW2+qrARJaHNbBDF9K/T9gx2C22mkTRTOEhj1ONy5Ee7dacvfi0Db0+22a6bWPrpq/hO2u2vbHFjzqT3J3TzHlidZ+dGRo6oydsLT3eG352t/L5m7bWHGsjlEMpKgJN/W3IKGu25RWly/o8Myd9tik2Dvv2nWzRa5BFsVujgXht9nT8xz/1N/r3s8Nn9nf//6bKO5D8djycJ1DeIvwA/ABmCaMSZRRB4RkXGu1d4GokRkK7a7qWx47VBgjYisxl74vtUYoxNjqxPDOQ/B5N9h3It2CO5lb8PNP8Mf58Ogyfak5K5Fb1thd/ZDtoDkwR1V77ek0CYUgJ+m2C6urmNsoup7LWSn2PlO3M39tz0ZLnjWJqya/PJfW2Nr7Wf2cVly6DraJqWGSBZOp51k7LPral+3LorybKVi9wKCLXod7obas9z+7nYBnPlXO0fN0rcr7qOhu4KyU21cCRPBWQw/P9Kwr18Nj95nYYyZZYw5zRjTyRjzmGvZg8aYma6/C4wxlxtjOhtjBhpjtruWf26MiTfG9DbG9DXG6D366sTh8IPm8Uexvq8tM3Lhc7ac+xvDDg+rBTt8NT/Tjp7Kz7B3qKeugfyDhwscnjbadm+teP/wdqlrbXLpcj4UZNpCitUpzrcTVwH8/LA9yZYlh2ZxtrusIS5yb5hpKwhv+NpOtnW8ykamhbtNC9Cip50LJXufPSkHhtsJxIbfa8vEfPcPSHINFV70GjzW0s5js/6r44+nLja7/u3P+JPrGtjHdu4bL9M7uJVqDHwcdmTULfPtqKtProQv/2R/Xh9qE8hvL9h5Oca/bIscBsdAp7Pt9r7+tu7Vpu/gi1tsmfapf7Anwktet8nk95fsRffsfbYF8ct/D3d7bfrOzm8y7B47SdXcx+xorabt7MRSMd2PbFmUltgS8TmukYjFBXbiqtkP21kOnU77U9OUwRlJ9joM2HXnP2GvwQRF2VaR02lvWvzuXvj8Zlu+vzDbzm1Sl+GuZQmuQsvC7SJ38nJo1ddWNPZx2DphEe3h8xvtENs5j0LzHnZOl2nXwsr/Vf06Tqd9/7VNA2zM4WO+f6NtHZYU2vc0Y7KdF2bd5/Yz0CzO/nuEt4Wvb7freZFWnVWqMYnsADfOtifNsusMA2+x3/ozkmDoP2zL5Zppdo4G9y6twX+3o2i2/GgvarfuB6OfsBfYR/7L3oH+9jl2+l6n6z6DrGS44BlY/QmEtbYnp/Sth2dFPM1Vxr5Zd3uN5LNJdiZE30D7Opk77bDUrqPsXe35GYdnQlzzmX2ctgEQOx9K1wtsccaQ5jZZrfzQ7j+0lR2xtH+9vWP+0B6b8J4+zZbocATY97r+K1tePz/DXqgeepc9ie7fYCcGy8+wCSyspa3rtfxdOwuje0uveQ+77ewpdrshfz/8XGA4XPYOvDnS/hgnXPmhHXjwyVUw8zZ7Mi/Isi22TmfD/MdtRWOwxyKqk+uni53SuFl3aN7TXmeaeZvdZ9O2kOwqOxLT3R6ztI2uGSSNbVGI2ER9wdPw8eW2izK0hd1v20F2FsuySdBKS2wL1YN08iOlGqu0TfZbaLNu9iLt4tfsiS04uubtnKX2InHZnOZlCnPsnA4ZSXbY78r/wYJn7EipohwYfLst5V5aAkm/2rIY3S60J/f9G+1w34JM20VVlGtPgv2vt/N9bPzGXp/pcy20OwPWfQHf32tPsoP+ZE/4W3923U/iOueIj30upBnsW2+/yQdH24KOJQV2zvvgaFtNuMt5tqT87IdtrANutK2Ljd/Y5BfVxSYKX397Et2/0Y486zQSLn7Nvoa7Td/bE3fufrjq0yPndvn9Rdv6GnaPnUQL7Pv+6s/2Hg1HwOGTfUA49LvOlpnJO2jv10jfao+zcV2obxJh44vpbls2BzbZ600xXeH7++y+r3jPthaXvAmD/2YTTpm5/7bdkCVF9vWdJTZpt+hpBzFEdbJTMR8DnSlPKVW7xC8haYHtZhn9hP12X1/KumR83Hq7s1Ntt1Tmbmgz0M4GeayMsQmmaVs7s2FleQftSbq6IcO56bDlB3sNyMdxZOzJS6B1/+q/saeus8OYe1xadQIvKbIJI2WlbXWFtrBDcytPiVyUa7uwgqOO3EdVivJg9yLbytq/ASI62Fbk6bfUbftKNFkopZSqVV2ThV7gVkopVStNFkoppWqlyUIppVStNFkopZSqlSYLpZRStdJkoZRSqlaaLJRSStVKk4VSSqlaabJQSilVK00WSimlaqXJQimlVK00WSillKqVJgullFK10mShlFKqVposlFJK1UqThVJKqVppslBKKVUrTRZKKaVqpclCKaVUrTRZKKWUqpUmC6WUUrXSZKGUUqpWmiyUUkrVSpOFUkqpWmmyUEopVStNFkoppWqlyUIppVStNFkopZSqlSYLpZRStdJkoZRSqlYeTRYiMkpENonIVhG5t4rnA0Rkquv5xSLS3u25+1zLN4nI+Z6MUymlVM08lixExAG8DIwG4oCrRCSu0mo3AhnGmM7As8ATrm3jgAlAPDAKeMW1P6WUUl7gyZbFQGCrMWa7MaYI+BQYX2md8cD7rr+nAyNFRFzLPzXGFBpjdgBbXftTSinlBb4e3HdrYLfb42Tg9OrWMcaUiEgWEOVavqjStq0rv4CI3ALc4nqYIyKbjiPeaODAcWzf0DRezzrR4oUTL2aN17PqGm+7uuzMk8lCqlhm6rhOXbbFGPMG8MbRh3YkEVlmjOlfH/tqCBqvZ51o8cKJF7PG61n1Ha8nu6GSgTZuj2OBlOrWERFfIBw4WMdtlVJKNRBPJoulQBcR6SAi/tgL1jMrrTMTuM7192XAHGOMcS2f4Bot1QHoAizxYKxKKaVq4LFuKNc1iL8APwAO4B1jTKKIPAIsM8bMBN4GPhSRrdgWxQTXtokiMg1YD5QAfzbGlHoqVpd66c5qQBqvZ51o8cKJF7PG61n1Gq/YL/JKKaVU9fQObqWUUrXSZKGUUqpWp3yyqK0kibeJSBsRmSsiG0QkUUT+5lr+kIjsEZFVrp8x3o7VnYgkichaV2zLXMsiReQnEdni+h3h7TgBRKSr23FcJSKHROT2xnSMReQdEdkvIuvcllV5PMV6wfWZXiMifRtJvP8VkY2umGaISFPX8vYiku92nF9r6HhriLnaz4C3SxJVE+9Ut1iTRGSVa/nxH2NjzCn7g73wvg3oCPgDq4E4b8dVKcaWQF/X36HAZmz5lIeAu7wdXw1xJwHRlZY9Cdzr+vte4Alvx1nNZyIVe6NSoznGwFCgL7CutuMJjAG+w96vNAhY3EjiPQ/wdf39hFu87d3Xa2THuMrPgOv/4GogAOjgOo84vB1vpeefBh6sr2N8qrcs6lKSxKuMMXuNMStcf2cDG6jibvYThHt5l/eBi7wYS3VGAtuMMTu9HYg7Y8wv2BGD7qo7nuOBD4y1CGgqIi0bJlKrqniNMT8aY0pcDxdh759qNKo5xtXxekmimuJ1lU26Avikvl7vVE8WVZUkabQnYldV3j7AYteiv7ia9O80li4dNwb4UUSWu8qyADQ3xuwFmwSBZl6LrnoTqPgfrDEf4+qO54nwub4B2/op00FEVorIfBE5y1tBVaOqz0BjP8ZnAfuMMVvclh3XMT7Vk0Wdyoo0BiISAnwO3G6MOQS8CnQCEoC92CZnYzLYGNMXW3X4zyIy1NsB1cZ18+g44DPXosZ+jKvTqD/XIvIA9v6pj1yL9gJtjTF9gDuAj0UkzFvxVVLdZ6BRH2PgKip+6TnuY3yqJ4sToqyIiPhhE8VHxpgvAIwx+4wxpcYYJ/AmjawqrzEmxfV7PzADG9++su4Q1+/93ouwSqOBFcaYfdD4jzHVH89G+7kWkeuAC4FrjKsz3dWVk+76ezm2//8070V5WA2fgcZ8jH2BS4CpZcvq4xif6smiLiVJvMrV9/g2sMEY84zbcvc+6IuBdZW39RYRCRaR0LK/sRc211GxvMt1wFfeibBaFb6NNeZj7FLd8ZwJXOsaFTUIyCrrrvImERkF3AOMM8bkuS2PEdd8NSLSEVveZ7t3oqyohs9AYy5JdA6w0RiTXLagXo5xQ169b4w/2JEjm7GZ9gFvx1NFfEOwzds1wCrXzxjgQ2Cta/lMoKW3Y3WLuSN2pMhqILHsuGLLz/8MbHH9jvR2rG4xBwHpQLjbskZzjLFJbC9QjP1We2N1xxPbRfKy6zO9FujfSOLdiu3nL/scv+Za91LX52Q1sAIY24iOcbWfAeAB1zHeBIxuDPG6lr8H3Fpp3eM+xlruQymlVK1O9W4opZRSdaDJQimlVK00WSillKqVJgullFK10mShlFKqVposlGoERGS4iHzj7TiUqo4mC6WUUrXSZKHUURCRiSKyxDUnwOsi4hCRHBF5WkRWiMjPIhLjWjdBRBa5zd9QNt9EZxGZLSKrXdt0cu0+RESmu+Z8+Mh1975SjYImC6XqSES6A1diiyQmAKXANUAwtqZUX2A+MMW1yQfAPcaYXti7gMuWfwS8bIzpDZyJvQsXbEXh27FzJXQEBnv8TSlVR77eDkCpE8hIoB+w1PWlvwm2eJ+Tw0Xb/gd8ISLhQFNjzHzX8veBz1w1s1obY2YAGGMKAFz7W2Jc9XxcM5y1BxZ4/m0pVTtNFkrVnQDvG2Puq7BQ5F+V1quphk5NXUuFbn+Xov8/VSOi3VBK1d3PwGUi0gzK58Buh/1/dJlrnauBBcaYLCDDbZKZPwDzjZ2LJFlELnLtI0BEghr0XSh1DPSbi1J1ZIxZLyL/xM4A6IOt9vlnIBeIF5HlQBb2ugbYsuGvuZLBduB61/I/AK+LyCOufVzegG9DqWOiVWeVOk4ikmOMCfF2HEp5knZDKaWUqpW2LJRSStVKWxZKKaVqpclCKaVUrTRZKKWUqpUmC6WUUrXSZKGUUqpW/w98E/fz0BaJOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training loss history\n",
    "    \n",
    "plt.plot(history_object.history['mean_absolute_error'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training loss (mae)','validation loss'],loc='upper right')\n",
    "plt.ylim([0,0.25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 184.58 556.00\" width=\"185pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 180.5758,-552 180.5758,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4923500624 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4923500624</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 176.5758,-547.5 176.5758,-511.5 0,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-525.3\">lambda_4_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4923437200 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4923437200</title>\n",
       "<polygon fill=\"none\" points=\"26.0512,-438.5 26.0512,-474.5 150.5246,-474.5 150.5246,-438.5 26.0512,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-452.3\">lambda_4: Lambda</text>\n",
       "</g>\n",
       "<!-- 4923500624&#45;&gt;4923437200 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4923500624-&gt;4923437200</title>\n",
       "<path d=\"M88.2879,-511.4551C88.2879,-503.3828 88.2879,-493.6764 88.2879,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-484.5903 88.2879,-474.5904 84.788,-484.5904 91.788,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4914833616 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4914833616</title>\n",
       "<polygon fill=\"none\" points=\"32.6655,-365.5 32.6655,-401.5 143.9103,-401.5 143.9103,-365.5 32.6655,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-379.3\">dense_13: Dense</text>\n",
       "</g>\n",
       "<!-- 4923437200&#45;&gt;4914833616 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4923437200-&gt;4914833616</title>\n",
       "<path d=\"M88.2879,-438.4551C88.2879,-430.3828 88.2879,-420.6764 88.2879,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-411.5903 88.2879,-401.5904 84.788,-411.5904 91.788,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4851141904 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4851141904</title>\n",
       "<polygon fill=\"none\" points=\"24.4881,-292.5 24.4881,-328.5 152.0877,-328.5 152.0877,-292.5 24.4881,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-306.3\">dropout_7: Dropout</text>\n",
       "</g>\n",
       "<!-- 4914833616&#45;&gt;4851141904 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4914833616-&gt;4851141904</title>\n",
       "<path d=\"M88.2879,-365.4551C88.2879,-357.3828 88.2879,-347.6764 88.2879,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-338.5903 88.2879,-328.5904 84.788,-338.5904 91.788,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4915077904 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4915077904</title>\n",
       "<polygon fill=\"none\" points=\"32.6655,-219.5 32.6655,-255.5 143.9103,-255.5 143.9103,-219.5 32.6655,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-233.3\">dense_14: Dense</text>\n",
       "</g>\n",
       "<!-- 4851141904&#45;&gt;4915077904 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4851141904-&gt;4915077904</title>\n",
       "<path d=\"M88.2879,-292.4551C88.2879,-284.3828 88.2879,-274.6764 88.2879,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-265.5903 88.2879,-255.5904 84.788,-265.5904 91.788,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4853608528 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4853608528</title>\n",
       "<polygon fill=\"none\" points=\"24.4881,-146.5 24.4881,-182.5 152.0877,-182.5 152.0877,-146.5 24.4881,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-160.3\">dropout_8: Dropout</text>\n",
       "</g>\n",
       "<!-- 4915077904&#45;&gt;4853608528 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4915077904-&gt;4853608528</title>\n",
       "<path d=\"M88.2879,-219.4551C88.2879,-211.3828 88.2879,-201.6764 88.2879,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-192.5903 88.2879,-182.5904 84.788,-192.5904 91.788,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4914279696 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>4914279696</title>\n",
       "<polygon fill=\"none\" points=\"32.6655,-73.5 32.6655,-109.5 143.9103,-109.5 143.9103,-73.5 32.6655,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-87.3\">dense_15: Dense</text>\n",
       "</g>\n",
       "<!-- 4853608528&#45;&gt;4914279696 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4853608528-&gt;4914279696</title>\n",
       "<path d=\"M88.2879,-146.4551C88.2879,-138.3828 88.2879,-128.6764 88.2879,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-119.5903 88.2879,-109.5904 84.788,-119.5904 91.788,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4854987728 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>4854987728</title>\n",
       "<polygon fill=\"none\" points=\"32.6655,-.5 32.6655,-36.5 143.9103,-36.5 143.9103,-.5 32.6655,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2879\" y=\"-14.3\">dense_16: Dense</text>\n",
       "</g>\n",
       "<!-- 4914279696&#45;&gt;4854987728 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>4914279696-&gt;4854987728</title>\n",
       "<path d=\"M88.2879,-73.4551C88.2879,-65.3828 88.2879,-55.6764 88.2879,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.788,-46.5903 88.2879,-36.5904 84.788,-46.5904 91.788,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize model\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
